# 游냊 M칩dulo de Hadoop: An치lisis de Big Data de La Liga

Este m칩dulo simula un entorno de **Hadoop** utilizando Python para procesar grandes vol칰menes de datos hist칩ricos de la liga espa침ola de f칰tbol. 

## 1. 쯈u칠 es Hadoop y por qu칠 es necesario?

**Hadoop** es un framework de c칩digo abierto que permite el almacenamiento y procesamiento distribuido de grandes conjuntos de datos (Big Data) a trav칠s de cl칰steres de computadoras. 

### 쯇or qu칠 lo usamos aqu칤?
En el mundo real, los datos de deportes no se limitan a un solo archivo .csv. Imagina procesar cada pase, cada posici칩n de GPS de 22 jugadores durante 90 minutos, en miles de partidos por temporada en todo el mundo.
- **Escalabilidad**: Hadoop permite procesar petabytes de datos que no cabr칤an en la memoria de un solo ordenador.
- **MapReduce**: Es el modelo de programaci칩n que usamos. Divide el problema en dos pasos (Map y Reduce).

### La Librer칤a: mrjob
Para implementar el modelo MapReduce sin necesidad de programar en Java (el lenguaje nativo de Hadoop), hemos utilizado **`mrjob`**. 
- **쯈u칠 hace?**: Permite escribir scripts de MapReduce en Python puro. 
- **Uso en este lab**: Se utiliza en `football_analysis_mr.py` y `advanced_stats_mr.py` para definir los pasos de mapeo (extraer datos de cada fila del CSV) y reducci칩n (sumar y agrupar resultados por equipo). 
- **Ventaja**: Facilita la ejecuci칩n de los trabajos tanto en local como en cl칰steres reales de Hadoop/EMR sin cambiar el c칩digo.

### Relaci칩n con herramientas comunes (Hive, Pig, HBase)
Aunque en este laboratorio hemos programado el **MapReduce directamente en Python**, es importante saber c칩mo se relaciona con las herramientas m치s famosas del ecosistema Hadoop:

1.  **Apache Hive**: Permite hacer consultas tipo SQL (`SELECT...`) sobre Hadoop. Lo que hemos hecho en `advanced_stats_mr.py` es exactamente lo que Hive har칤a "por debajo": transformar una consulta de base de datos en c칩digo MapReduce.
2.  **Apache Pig**: Es un lenguaje de flujo de datos. Mientras Pig usa un lenguaje llamado Pig Latin, nosotros usamos la librer칤a `mrjob` de Python, que simplifica el flujo de datos de forma similar.
3.  **Apache HBase**: Es una base de datos NoSQL para acceso en tiempo real. En este lab no la usamos porque nuestros datos son est치ticos (archivos CSV), pero en un entorno profesional, los resultados del an치lisis podr칤an guardarse en HBase para ser consultados instant치neamente.

---

## 2. Estructura de la Carpeta `hadoop_lab`

A continuaci칩n, se detalla la funci칩n de cada archivo contenido en esta carpeta:

| Archivo | Tipo | Descripci칩n |
| :--- | :--- | :--- |
| `requirements.txt` | Config | Lista de librer칤as necesarias (`mrjob`, `pandas`, `requests`). |
| `prepare_data.py` | Python | **Extractor**: Descarga datos desde Football-Data.co.uk y los unifica en un solo archivo maestro. |
| `football_analysis_mr.py`| Python | **MapReduce B치sico**: Script inicial de prueba para contar goles totales por equipo. |
| `advanced_stats_mr.py` | Python | **MapReduce Avanzado**: El "motor" principal. Calcula goles, tarjetas rojas y victorias simult치neamente. |
| `analyze_results.py` | Python | **Procesador**: Lee la salida bruta de Hadoop y genera rankings legible en la terminal. |
| `final_stats.py` | Python | **Reportador**: Genera el informe final del MapReduce. |
| `spark_analysis.py` | Python | **Spark SQL**: An치lisis avanzado usando SQL sobre el cl칰ster. |
| `spark_reporte.txt` | Texto | **Informe Spark**: Resultado de las consultas SQL avanzadas. |
| `run_analysis.ps1` | PowerShell | **Orquestador**: Automatiza el flujo completo de MapReduce. |

---

## 3. Flujo de Informaci칩n (Compilaci칩n de Datos)

### A. Flujo de Hadoop (MapReduce Cl치sico)
1.  **Entrada**: `laliga_history.csv`.
2.  **`football_analysis_mr.py`** 俱뫮잺 Genera **`resultados.txt`** (conteo simple de goles).
3.  **`advanced_stats_mr.py`** 俱뫮잺 Genera **`advanced_results.txt`** (datos "raw" de Hadoop).
4.  **`final_stats.py`** 俱뫮잺 Genera **`final_report.txt`** (resumen final legible).

### B. Flujo de Spark (An치lisis Moderno)
1.  **Entrada**: `laliga_history.csv`.
2.  **`spark_analysis.py`** 俱뫮잺 Los resultados se ven en consola por defecto.
3.  **Redirecci칩n de salida** 俱뫮잺 Si usas `> hadoop_lab/spark_results.txt` o `spark_reporte.txt`, guardas las tablas de SQL en esos archivos para persistencia.

---

## 4. Integraci칩n con el Dashboard
Los datos procesados en `laliga_history.csv` son los mismos que consume el **Dashboard Interactivo** (`www/hadoop.html`), permitiendo que la visualizaci칩n web sea siempre fiel a los datos analizados por el motor de Hadoop.

## 5. An치lisis Moderno: Spark SQL (Alternativa a Hive)

Para este m칩dulo hemos utilizado **PySpark** y el motor de **Spark SQL**, que permite procesar datos distribuidos utilizando el lenguaje SQL est치ndar, tal como se har칤a profesionalmente con Apache Hive.

### Herramientas y Librer칤as:
- **PySpark**: API de Python para Apache Spark.
- **Spark SQL**: Motor para el procesamiento de datos estructurados.
- **Spark Master/Workers**: Cl칰ster distribuido corriendo en contenedores Docker.

### C칩mo ejecutar el an치lisis:
> [!IMPORTANT]
> **Antes de empezar**: Si has cerrado la terminal, primero debes situarte en la carpeta del proyecto. De lo contrario, los archivos de reporte no se guardar치n en el sitio correcto.
> ```powershell
> cd c:\Users\alexi\Downloads\Prueba_Script_Docker
> ```

1. Abrir una terminal en la ra칤z del proyecto (ver nota arriba).
2. Ejecutar el comando para procesar y guardar el reporte:
   ```powershell
   docker exec spark-master /opt/spark/bin/spark-submit /opt/spark/scripts/spark_analysis.py > hadoop_lab/spark_reporte.txt
   ```

### Consultas Implementadas:
El script `spark_analysis.py` ejecuta consultas complejas de nivel profesional:
- **Top 10 Goles**: An치lisis global de ataque.
- **Top 5 Rojas**: An치lisis de disciplina.
- **Eficiencia Global**: Relaci칩n victorias/partidos.
- **Especialistas Visitantes**: SQL Complejo que filtra y calcula el % de victorias solo fuera de casa.
- **Evoluci칩n por Temporada**: Agrupaci칩n temporal para detectar tendencias de promedio de gol.

### Monitoreo (Spark Web UI):
Mientras el cl칰ster est치 encendido, puedes entrar a [http://localhost:8080](http://localhost:8080) para ver:
- El estado de los Workers.
- Las aplicaciones completadas (`LaLigaSparkSQL_Advanced`).
- El tiempo de ejecuci칩n y recursos utilizados.

---

## 6. Visualizaci칩n Final (Dashboard)

El resultado final de todos estos an치lisis se puede visualizar de forma interactiva en la interfaz web del proyecto.

### Acceso Directo:
游녤 **[http://localhost:8081/hadoop.html](http://localhost:8081/hadoop.html)**

### Vista Previa:
![Dashboard Hadoop](../images/Hadoop_Pages.png)

---

> **Nota de Copyright**: Los datos utilizados en este laboratorio son propiedad de [Football-Data.co.uk](https://www.football-data.co.uk) y se utilizan exclusivamente con fines educativos y de demostraci칩n t칠cnica.
